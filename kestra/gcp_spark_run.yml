id: gcp_spark_run
namespace: ghg_project
description: "Job to upload pyspark script to gcs bucket and submit job to dataproc"

tasks:
  - id: submit_pyspark_job
    type: "io.kestra.plugin.gcp.cli.GCloudCLI"
    projectId: "{{kv('GCP_PROJECT_ID')}}"
    serviceAccount: "{{kv('GCP_CREDS')}}"
    commands: 
    - gcloud dataproc jobs submit pyspark gs://{{kv('GCP_BUCKET_NAME')}}/scripts/transform_ghg_data.py --cluster="{{kv('GCP_CLUSTER')}}" --region="{{kv('GCP_REGION')}}" --project="{{kv('GCP_PROJECT_ID')}}" -- --input_year "{{execution.startDate | date('yyyy')}}"
      
pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{kv('GCP_CREDS')}}"
      projectId: "{{kv('GCP_PROJECT_ID')}}"
      location: "{{kv('GCP_LOCATION')}}"
      bucket: "{{kv('GCP_BUCKET_NAME')}}"
      dataset: "{{kv('GCP_DATASET')}}"
      cluster: "{{kv('GCP_CLUSTER')}}"
      region: "{{kv('GCP_REGION')}}"