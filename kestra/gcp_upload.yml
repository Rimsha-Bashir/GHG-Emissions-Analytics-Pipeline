id: gcp_upload
namespace: ghg_project
description: "Scheduled job to download OWID CO2 data and upload it to GCS"

variables:
  file: "emissions_data.csv"
  gcs_file: "gs://{{kv('GCP_BUCKET_NAME')}}/raw/{{vars.file}}"
  data: "{{outputs.extract.outputFiles['emissions_data' ~ '.csv']}}"

tasks:
  - id: extract
    type: io.kestra.plugin.scripts.shell.Commands
    outputFiles:
      - "*.csv"
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    commands:
      - wget -q -O "{{render(vars.file)}}" "https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.csv"

  - id: upload_to_gcs
    type: io.kestra.plugin.gcp.gcs.Upload
    from: "{{render(vars.data)}}"
    to: "{{render(vars.gcs_file)}}"
  
  - id: purge_files
    type: io.kestra.plugin.core.storage.PurgeCurrentExecutionFiles
    description: To avoid cluttering your storage, we will remove the downloaded files

pluginDefaults:
  - type: io.kestra.plugin.gcp
    values:
      serviceAccount: "{{kv('GCP_CREDS')}}"
      projectId: "{{kv('GCP_PROJECT_ID')}}"
      location: "{{kv('GCP_LOCATION')}}"
      bucket: "{{kv('GCP_BUCKET_NAME')}}"
      dataset: "{{kv('GCP_DATASET')}}"

triggers:
  - id: yearly_schedule
    type: io.kestra.plugin.core.trigger.Schedule
    cron: "0 0 1 1 *"